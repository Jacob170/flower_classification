{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":773427,"sourceType":"datasetVersion","datasetId":403293}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# Create a folder for the raw images\n!mkdir -p /kaggle/working/data/raw\n\n# Unzip the .tgz file (Adjust the path if yours is slightly different)\n!tar -xzf \"/kaggle/input/flower-dataset-102/102flowers.tgz\" -C /kaggle/working/data/raw\n\nimport os\nimport os\nimage_dir = \"/kaggle/working/data/raw/jpg\" # Check if tar created a 'jpg' subfolder\nif not os.path.exists(image_dir):\n    image_dir = \"/kaggle/working/data/raw\"\n\nnum_images = len([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\nprint(f\"Total images extracted: {num_images}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-01T19:00:44.016669Z","iopub.execute_input":"2026-02-01T19:00:44.016851Z","iopub.status.idle":"2026-02-01T19:00:49.025366Z","shell.execute_reply.started":"2026-02-01T19:00:44.016816Z","shell.execute_reply":"2026-02-01T19:00:49.024500Z"}},"outputs":[{"name":"stdout","text":"Total images extracted: 8189\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nimport scipy.io\nfrom sklearn.model_selection import train_test_split\n\n\n# --- KAGGLE PATH ADJUSTMENTS ---\n# Replace 'oxford-102-flower-dataset' with the actual folder name from os.listdir('/kaggle/input')\nDATASET_NAME = 'flower-dataset-102' \nRAW_DIR = \"/kaggle/working/data/raw/jpg\"  # Kaggle usually puts images in a 'jpg' folder\nLABELS_FILE = \"/kaggle/input/flower-dataset-102/imagelabels.mat\"\nOUTPUT_DIR = \"/kaggle/working/data/splits\"\n# -------------------------------\n\ndef get_images_and_labels():\n    \"\"\"Load all images and labels\"\"\"\n    # Get image paths - using full paths\n    images = sorted(\n        [os.path.join(RAW_DIR, f) for f in os.listdir(RAW_DIR) if f.endswith(\".jpg\")]\n    )\n\n    # Load labels (convert from 1-102 to 0-101)\n    labels = scipy.io.loadmat(LABELS_FILE)[\"labels\"][0] - 1\n    return images, labels\n\ndef create_split(images, labels, seed):\n    \"\"\"Create one train/val/test split\"\"\"\n    train_imgs, temp_imgs, train_labels, temp_labels = train_test_split(\n        images, labels, test_size=0.5, random_state=seed, stratify=labels\n    )\n\n    val_imgs, test_imgs, val_labels, test_labels = train_test_split(\n        temp_imgs, temp_labels, test_size=0.5, random_state=seed, stratify=temp_labels\n    )\n\n    split_dir = os.path.join(OUTPUT_DIR, f\"split_{seed}\")\n\n    for split_name, imgs, lbls in [\n        (\"train\", train_imgs, train_labels),\n        (\"val\", val_imgs, val_labels),\n        (\"test\", test_imgs, test_labels),\n    ]:\n        for img, label in zip(imgs, lbls):\n            class_folder = os.path.join(split_dir, split_name, f\"class_{label:03d}\")\n            os.makedirs(class_folder, exist_ok=True)\n            # Use copy instead of copy2 if you run into permission issues on Kaggle\n            shutil.copy(img, class_folder)\n\n    print(f\"Split {seed}: Train={len(train_imgs)}, Val={len(val_imgs)}, Test={len(test_imgs)}\")\n\n\nimages, labels = get_images_and_labels()\nprint(f\"Total images: {len(images)}, Classes: {len(set(labels))}\")\n\n# Create 2 splits\ncreate_split(images, labels, seed=42)\ncreate_split(images, labels, seed=123)\nprint(f\"\\nDone! Splits saved in {OUTPUT_DIR}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T19:01:46.009960Z","iopub.execute_input":"2026-02-01T19:01:46.010788Z","iopub.status.idle":"2026-02-01T19:01:49.250041Z","shell.execute_reply.started":"2026-02-01T19:01:46.010748Z","shell.execute_reply":"2026-02-01T19:01:49.249361Z"}},"outputs":[{"name":"stdout","text":"Total images: 8189, Classes: 102\nSplit 42: Train=4094, Val=2047, Test=2048\nSplit 123: Train=4094, Val=2047, Test=2048\n\nDone! Splits saved in /kaggle/working/data/splits\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"Noiw we goign to preproccess   lets define how preproccess works first ","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom torchvision import transforms\n\n\ndef preprocess_for_vgg19():\n    \"\"\"\n    Resize to 224x224\n    Normalize pixel values\n    Apply VGG19-specific preprocessing\n    \"\"\"\n    # For TRAINING data (with augmentation)\n\n    train_transform = transforms.Compose(\n        [\n            transforms.Resize((224, 224)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ]\n    )\n    # For VALIDATION/TEST data (NO augmentation)\n\n    test_transform = transforms.Compose(\n        [\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ]\n    )\n\n    return train_transform, test_transform\n\n\ndef preprocess_for_yolov5():\n    \"\"\"\n    Resize to 640x640\n    Normalize\n    Apply YOLOv5-specific preprocessing\n    \"\"\"\n    # For TRAINING data (with augmentation)\n\n    train_transform = transforms.Compose(\n        [\n            transforms.Resize((244, 244)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ]\n    )\n    # For VALIDATION/TEST data (NO augmentation)\n\n    test_transform = transforms.Compose(\n        [\n            transforms.Resize((244, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ]\n    )\n    return train_transform, test_transform\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T19:29:59.583970Z","iopub.execute_input":"2026-02-01T19:29:59.584744Z","iopub.status.idle":"2026-02-01T19:29:59.591547Z","shell.execute_reply.started":"2026-02-01T19:29:59.584711Z","shell.execute_reply":"2026-02-01T19:29:59.590843Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Evaluation fucntion \n\nimport matplotlib.pyplot as plt\n\ndef plot_cross_entropy_loss(history, model_name, split_name, test_loss):\n    \"\"\"\n    Calculate accuracy\n    Generate confusion matrix\n    Plot accuracy and loss curves\n    \"\"\"\n\n    # the losses and epochs lists\n    train_losses = history[\"train_loss\"]\n    val_losses = history[\"val_loss\"]\n\n    epochs = range(1, len(history[\"train_loss\"]) + 1)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=2)\n    plt.plot(epochs, val_losses, 'g-', label='Validation Loss', linewidth=2)\n    plt.axhline(y=test_loss, color='r', linestyle='--', label=f'Test Loss: {test_loss:.4f}', linewidth=2)\n    plt.title(f'Cross-Entropy Loss - {model_name.upper()} ({split_name})', fontsize=14)\n    plt.xlabel('Epoch', fontsize=12)\n    plt.ylabel('Loss', fontsize=12)\n    plt.legend(loc='upper right')\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n\n    os.makedirs('results/graphs', exist_ok=True)\n    save_path = f'results/graphs/{model_name}_{split_name}_loss.png'\n    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    plt.close()  # Close to free memory\n    print(f\"Saved: {save_path}\")\n\n\ndef plot_accuracy_graph(history, model_name, split_name, test_acc):\n    epochs = range(1, len(history[\"train_loss\"]) + 1)\n\n    train_acc = history[\"train_acc\"]\n    val_acc = history[\"val_acc\"]\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(epochs, train_acc, 'b-', label='Train Accuracy', linewidth=2)\n    plt.plot(epochs, val_acc, 'g-', label='Validation Accuracy', linewidth=2)\n    plt.axhline(y=test_acc, color='r', linestyle='--', label=f'Test Accuracy: {test_acc:.2f}%', linewidth=2)\n    plt.title(f'Accuracy - {model_name.upper()} ({split_name})', fontsize=14)\n    plt.xlabel('Epoch', fontsize=12)\n    plt.ylabel('Accuracy (%)', fontsize=12)\n    plt.legend(loc='lower right')\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    os.makedirs('results/graphs', exist_ok=True)\n    save_path = f'results/graphs/{model_name}_{split_name}_accuracy.png'\n    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    plt.close()  # Close to free memory\n    print(f\"Saved: {save_path}\")\n\nprint(\"defined plotting methods\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T19:29:41.057058Z","iopub.execute_input":"2026-02-01T19:29:41.058095Z","iopub.status.idle":"2026-02-01T19:29:41.068981Z","shell.execute_reply.started":"2026-02-01T19:29:41.058039Z","shell.execute_reply":"2026-02-01T19:29:41.068310Z"}},"outputs":[{"name":"stdout","text":"defined plotting methods\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Imstall yolo","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T19:02:12.709413Z","iopub.execute_input":"2026-02-01T19:02:12.709704Z","iopub.status.idle":"2026-02-01T19:02:18.434127Z","shell.execute_reply.started":"2026-02-01T19:02:12.709680Z","shell.execute_reply":"2026-02-01T19:02:18.433338Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.4.9-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\nDownloading ultralytics-8.4.9-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.4.9 ultralytics-thop-2.0.18\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"**Load all whats needed **","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\nfrom ultralytics import YOLO\nimport sys","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T19:02:30.424891Z","iopub.execute_input":"2026-02-01T19:02:30.425577Z","iopub.status.idle":"2026-02-01T19:02:30.837183Z","shell.execute_reply.started":"2026-02-01T19:02:30.425539Z","shell.execute_reply":"2026-02-01T19:02:30.836542Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# VGG19 - IMPROVED VERSION\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nNUM_CLASSES = 102\nEPOCHS = 35\nLEARNING_RATE = 0.01\n\n\nclass VGG19Classifier(nn.Module):\n    def __init__(self, num_classes=102):\n        super().__init__()\n\n        # Load pretrained VGG19\n        self.backbone = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n\n        # Freeze features (conv layers) only\n        for param in self.backbone.features.parameters():\n            param.requires_grad = False\n\n        # Replace the last layer\n        self.backbone.classifier[6] = nn.Linear(4096, num_classes)\n\n        self.model = self.backbone.to(DEVICE)\n\n        self.criterion = nn.CrossEntropyLoss()\n        \n        # Use SGD with momentum (often better for transfer learning)\n        self.optimizer = torch.optim.SGD(\n            self.model.classifier.parameters(),\n            lr=LEARNING_RATE,\n            momentum=0.9,\n            weight_decay=1e-4\n        )\n        \n        # Learning rate scheduler\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            self.optimizer,\n            mode='max',\n            factor=0.1,\n            patience=3,\n            verbose=True\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n    def train_model(self, train_loader=None, val_loader=None):\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        self.history = {\n            \"train_loss\": [],\n            \"train_acc\": [],\n            \"val_loss\": [],\n            \"val_acc\": [],\n        }\n\n        best_val_acc = 0\n\n        for epoch in range(EPOCHS):\n            # Train\n            self.model.train()\n            train_loss = 0\n            train_correct = 0\n\n            for images, labels in self.train_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n                self.optimizer.zero_grad()\n                outputs = self.forward(images)\n                loss = self.criterion(outputs, labels)\n                loss.backward()\n                self.optimizer.step()\n\n                train_loss += loss.item()\n                train_correct += (outputs.argmax(1) == labels).sum().item()\n\n            train_acc = 100 * train_correct / len(self.train_loader.dataset)\n            avg_train_loss = train_loss / len(self.train_loader)\n\n            # Validate\n            self.model.eval()\n            val_correct = 0\n            val_loss = 0\n            with torch.no_grad():\n                for images, labels in self.val_loader:\n                    images, labels = images.to(DEVICE), labels.to(DEVICE)\n                    outputs = self.forward(images)\n                    val_correct += (outputs.argmax(1) == labels).sum().item()\n                    val_loss += self.criterion(outputs, labels).item()\n\n            val_acc = 100 * val_correct / len(self.val_loader.dataset)\n            avg_val_loss = val_loss / len(self.val_loader)\n\n            # Step scheduler based on validation accuracy\n            self.scheduler.step(val_acc)\n\n            # Track best\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n\n            self.history[\"train_loss\"].append(avg_train_loss)\n            self.history[\"train_acc\"].append(train_acc)\n            self.history[\"val_loss\"].append(avg_val_loss)\n            self.history[\"val_acc\"].append(val_acc)\n\n            # Get current learning rate\n            current_lr = self.optimizer.param_groups[0]['lr']\n            print(f\"Epoch {epoch+1}/{EPOCHS} - Train: {train_acc:.2f}% - Val: {val_acc:.2f}% - LR: {current_lr:.6f}\")\n\n        print(f\"\\nBest Validation Accuracy: {best_val_acc:.2f}%\")\n        return self.history\n\n    def test_model(self, test_loader=None):\n        self.test_loader = test_loader\n        self.model.eval()\n        test_correct = 0\n        test_loss = 0\n\n        with torch.no_grad():\n            for images, labels in self.test_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = self.forward(images)\n                test_correct += (outputs.argmax(1) == labels).sum().item()\n                test_loss += self.criterion(outputs, labels).item()\n\n        test_acc = 100 * test_correct / len(self.test_loader.dataset)\n        avg_test_loss = test_loss / len(self.test_loader)\n\n        print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n        return test_acc, avg_test_loss\n\nprint(\"success\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T22:06:08.671609Z","iopub.execute_input":"2026-02-01T22:06:08.672546Z","iopub.status.idle":"2026-02-01T22:06:08.689089Z","shell.execute_reply.started":"2026-02-01T22:06:08.672490Z","shell.execute_reply":"2026-02-01T22:06:08.688382Z"}},"outputs":[{"name":"stdout","text":"success\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# VGG19 - WORKING VERSION\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nNUM_CLASSES = 102\nEPOCHS = 35\n\nLEARNING_RATE = 0.001\n\n\nclass VGG19Classifier(nn.Module):\n    def __init__(self, num_classes=102):\n        super().__init__()\n\n        # Load pretrained VGG19\n        self.backbone = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n\n        # Freeze features (conv layers) only\n        for param in self.backbone.features.parameters():\n            param.requires_grad = False\n\n        # Replace ONLY the last layer (4096 → 102)\n        self.backbone.classifier[6] = nn.Linear(4096, num_classes)\n\n        self.model = self.backbone.to(DEVICE)\n\n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = torch.optim.Adam(\n            self.model.classifier.parameters(),  # Train entire classifier\n            lr=LEARNING_RATE\n        )\n\n        \n\n    def forward(self, x):\n        return self.model(x)\n\n    def train_model(self, train_loader=None, val_loader=None):\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        self.history = {\n            \"train_loss\": [],\n            \"train_acc\": [],\n            \"val_loss\": [],\n            \"val_acc\": [],\n        }\n\n        for epoch in range(EPOCHS):\n            # Train\n            self.model.train()\n            train_loss = 0\n            train_correct = 0\n\n            for images, labels in self.train_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n                self.optimizer.zero_grad()\n                outputs = self.forward(images)\n                loss = self.criterion(outputs, labels)\n                loss.backward()\n                self.optimizer.step()\n\n                train_loss += loss.item()\n                train_correct += (outputs.argmax(1) == labels).sum().item()\n\n            train_acc = 100 * train_correct / len(self.train_loader.dataset)\n            avg_train_loss = train_loss / len(self.train_loader)\n\n            # Validate\n            self.model.eval()\n            val_correct = 0\n            val_loss = 0\n            with torch.no_grad():\n                for images, labels in self.val_loader:\n                    images, labels = images.to(DEVICE), labels.to(DEVICE)\n                    outputs = self.forward(images)\n                    val_correct += (outputs.argmax(1) == labels).sum().item()\n                    val_loss += self.criterion(outputs, labels).item()\n\n            val_acc = 100 * val_correct / len(self.val_loader.dataset)\n            avg_val_loss = val_loss / len(self.val_loader)\n\n            self.history[\"train_loss\"].append(avg_train_loss)\n            self.history[\"train_acc\"].append(train_acc)\n            self.history[\"val_loss\"].append(avg_val_loss)\n            self.history[\"val_acc\"].append(val_acc)\n\n            print(f\"Epoch {epoch+1}/{EPOCHS} - Train: {train_acc:.2f}% - Val: {val_acc:.2f}%\")\n\n        return self.history\n\n    def test_model(self, test_loader=None):\n        self.test_loader = test_loader\n        self.model.eval()\n        test_correct = 0\n        test_loss = 0\n\n        with torch.no_grad():\n            for images, labels in self.test_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = self.forward(images)\n                test_correct += (outputs.argmax(1) == labels).sum().item()\n                test_loss += self.criterion(outputs, labels).item()\n\n        test_acc = 100 * test_correct / len(self.test_loader.dataset)\n        avg_test_loss = test_loss / len(self.test_loader)\n\n        print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n        return test_acc, avg_test_loss\n\nprint(\"success\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T21:05:17.005100Z","iopub.execute_input":"2026-02-01T21:05:17.005894Z","iopub.status.idle":"2026-02-01T21:05:17.019712Z","shell.execute_reply.started":"2026-02-01T21:05:17.005856Z","shell.execute_reply":"2026-02-01T21:05:17.019110Z"}},"outputs":[{"name":"stdout","text":"success\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Add yolov5 to path (if you cloned it)\nsys.path.append(\"../yolov5\")\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nNUM_CLASSES = 102\nEPOCHS = 20\nLEARNING_RATE = 0.001\nMODEL_WEIGHTS = \"yolov5s-cls.pt\"\n\nclass YOLOv5Classifier(nn.Module):\n    def __init__(self, num_classes=102):\n        super().__init__()\n\n        # Load YOLOv5 CLASSIFICATION model from Torch Hub\n        # Path should just be the filename; it will auto-download to /kaggle/working\n        self.backbone = torch.hub.load(\n            \"ultralytics/yolov5\",\n            \"custom\",\n            path=MODEL_WEIGHTS, \n            trust_repo=True,\n        )\n\n        # Freeze backbone (layers 0-8), keep head (layer 9) trainable\n        freeze_layers = [\n            \"model.0.\",\n            \"model.1.\",\n            \"model.2.\",\n            \"model.3.\",\n            \"model.4.\",\n            \"model.5.\",\n            \"model.6.\",\n            \"model.7.\",\n            \"model.8.\",\n        ]\n\n        for name, param in self.backbone.model.named_parameters():\n            if any(layer in name for layer in freeze_layers):\n                param.requires_grad = False  # Freeze backbone\n            else:\n                param.requires_grad = True  # Train head (layer 9)\n\n        # Replace final linear layer: 1000 classes → 102 classes\n        # model.9.linear is the classification layer\n        in_features = self.backbone.model.model[9].linear.in_features  # 1280\n        self.backbone.model.model[9].linear = nn.Linear(in_features, num_classes)\n\n        self.model = self.backbone.to(DEVICE)\n\n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = torch.optim.Adam(\n            filter(lambda p: p.requires_grad, self.model.parameters()), lr=LEARNING_RATE\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n    def train_model(self, train_loader=None, val_loader=None):\n\n        # 0. Store data loaders\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        # Store history for plotting later\n        self.history = {\n            \"train_loss\": [],\n            \"train_acc\": [],\n            \"val_loss\": [],\n            \"val_acc\": [],\n        }\n        # ============================================\n        # TRAINING LOOP\n        # ============================================\n        for epoch in range(EPOCHS):\n            # Train\n            self.model.train()\n            train_loss = 0\n            train_correct = 0\n\n            for images, labels in self.train_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n                self.optimizer.zero_grad()\n                outputs = self.forward(images)\n                loss = self.criterion(outputs, labels)\n                loss.backward()\n                self.optimizer.step()\n\n                train_loss += loss.item()\n                train_correct += (outputs.argmax(1) == labels).sum().item()\n\n            train_acc = 100 * train_correct / len(self.train_loader.dataset)\n            avg_train_loss = train_loss / len(self.train_loader)\n\n            # Validate\n            self.model.eval()\n            val_correct = 0\n            val_loss = 0\n            with torch.no_grad():\n                for images, labels in self.val_loader:\n                    images, labels = images.to(DEVICE), labels.to(DEVICE)\n                    outputs = self.forward(images)\n                    val_correct += (outputs.argmax(1) == labels).sum().item()\n                    # add loss calculation for validation\n                    val_loss += self.criterion(outputs, labels).item()\n\n            val_acc = 100 * val_correct / len(self.val_loader.dataset)\n            avg_val_loss = val_loss / len(self.val_loader)\n\n            self.history[\"train_loss\"].append(avg_train_loss)\n            self.history[\"train_acc\"].append(train_acc)\n            self.history[\"val_loss\"].append(avg_val_loss)\n            self.history[\"val_acc\"].append(val_acc)\n\n            print(\n                f\"Epoch {epoch+1}/{EPOCHS} - Train: {train_acc:.2f}% - Val: {val_acc:.2f}%\"\n            )\n        return self.history\n\n    def test_model(self, test_loader=None):\n        self.test_loader = test_loader\n        # ============================================\n        # TEST\n        # ============================================\n        self.model.eval()\n        test_correct = 0\n        test_loss = 0\n\n        with torch.no_grad():\n            for images, labels in self.test_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = self.forward(images)\n                test_correct += (outputs.argmax(1) == labels).sum().item()\n                test_loss += self.criterion(outputs, labels).item()\n\n        test_acc = 100 * test_correct / len(self.test_loader.dataset)\n        print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n        test_loss = test_loss / len(self.test_loader)\n        return test_acc, test_loss\n\nprint(\"loaded yolo\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T19:30:22.522294Z","iopub.execute_input":"2026-02-01T19:30:22.522961Z","iopub.status.idle":"2026-02-01T19:30:22.536945Z","shell.execute_reply.started":"2026-02-01T19:30:22.522928Z","shell.execute_reply":"2026-02-01T19:30:22.536122Z"}},"outputs":[{"name":"stdout","text":"loaded yolo\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**train loops**","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\nimport torch\nimport time\n\nmodel_names = [\"yolo\", \"vgg\"]\nsplits = [\"split_42\", \"split_123\"]\n\nfor m_name in model_names:\n    for split in splits:\n\n        # loading transform fucntions\n        if m_name == \"vgg\":\n            train_transform, test_transform = preprocess_for_vgg19()\n            classifier = VGG19Classifier()\n            print(\"training vgg19\")\n        else:\n            continue\n            # train_transform, test_transform = preprocess_for_yolov5()\n            # classifier = YOLOv5Classifier()\n\n        train_dataset = ImageFolder(\n            f\"/kaggle/working/data/splits/{split}/train\", transform=train_transform\n        )\n        val_dataset = ImageFolder(\n            f\"/kaggle/working/data/splits/{split}/val\", transform=test_transform\n        )\n        test_dataset = ImageFolder(\n            f\"/kaggle/working/data/splits/{split}/test\", transform=test_transform\n        )\n\n        # Create dataloaders\n        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n\n        # def test_gpu_speed(classifier, label=\"Model\"):\n        #     # Move model to device\n        #     classifier.to(DEVICE)\n        #     classifier.eval()\n            \n        #     # Create 50 batches of fake data (Noise)\n        #     dummy_input = torch.randn(16, 3, 224, 224).to(DEVICE)\n            \n        #     print(f\"--- Testing {label} on GPU ---\")\n        #     start = time.time()\n        #     with torch.no_grad():\n        #         for _ in range(50):\n        #             _ = classifier(dummy_input)\n        #     end = time.time()\n            \n        #     print(f\"Finished 50 batches in {end - start:.2f} seconds.\")\n        #     print(f\"Approx {50/(end-start):.2f} batches per second.\\n\")\n        \n        # # Run for both\n        # test_gpu_speed(YOLOv5Classifier(), \"YOLOv5\")\n        # test_gpu_speed(VGG19Classifier(), \"VGG19\")\n\n        # print(f\"Model: {m_name.upper()}, Split: {split}\")\n\n        history = classifier.train_model(\n            train_loader=train_loader, val_loader=val_loader\n        )\n        test_acc, test_loss = classifier.test_model(test_loader=test_loader)\n\n        plot_cross_entropy_loss(\n            history, model_name=m_name, split_name=split, test_loss=test_loss\n        )\n        plot_accuracy_graph(\n            history, model_name=m_name, split_name=split, test_acc=test_acc\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T22:06:24.162294Z","iopub.execute_input":"2026-02-01T22:06:24.162818Z","iopub.status.idle":"2026-02-01T22:06:25.790200Z","shell.execute_reply.started":"2026-02-01T22:06:24.162778Z","shell.execute_reply":"2026-02-01T22:06:25.789247Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1310807884.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"vgg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_for_vgg19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG19Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training vgg19\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/3205140655.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Learning rate scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"],"ename":"TypeError","evalue":"ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'","output_type":"error"}],"execution_count":28}]}